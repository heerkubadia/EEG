{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne import Epochs, pick_types, find_events\n",
    "from mne.channels import read_layout\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mne import Epochs, pick_types, find_events\n",
    "from mne.channels import read_layout\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne import events_from_annotations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(__doc__)\n",
    "tmin, tmax = -1., 4.\n",
    "event_id = dict(hands=2, feet=3)\n",
    "subject = 1\n",
    "runs = [6, 10, 14]  # motor imagery: hands vs feet\n",
    "\n",
    "raw_fnames = eegbci.load_data(subject, runs)\n",
    "raw_files = [read_raw_edf(f, preload=True) for f in raw_fnames]\n",
    "raw = concatenate_raws(raw_files)\n",
    "\n",
    "# strip channel names of \".\" characters\n",
    "raw.rename_channels(lambda x: x.strip('.'))\n",
    "\n",
    "# Apply band-pass filter\n",
    "raw.filter(7., 30.)\n",
    "\n",
    "\n",
    "# Convert annotations to events\n",
    "events, _ = events_from_annotations(raw)\n",
    "picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                baseline=None, preload=True)\n",
    "epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "epochs_test = epochs.copy().crop(tmin=2., tmax=3.)  # Adjust time window for test data\n",
    "labels_train = epochs_train.events[:, -1] - 2\n",
    "labels_test = epochs_test.events[:, -1] - 2\n",
    "# Data normalization\n",
    "X_train = epochs_train.get_data()\n",
    "X_test = epochs_test.get_data()\n",
    "mean, std = X_train.mean(), X_train.std()\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Data augmentation\n",
    "def augment_data(X):\n",
    "    return np.flip(X, axis=-1)  # Horizontal flip\n",
    "\n",
    "X_train_augmented = augment_data(X_train)\n",
    "X_train = np.concatenate((X_train, X_train_augmented), axis=0)\n",
    "labels_train = np.concatenate((labels_train, labels_train), axis=0)\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train and X_test are your input data arrays\n",
    "X_train = X_train.reshape(-1, 64, 161, 1)  # Reshape for one channel\n",
    "X_test = X_test.reshape(-1, 64, 161, 1)\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(labels_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(labels_test, dtype=torch.long)\n",
    "# Define a simple fully connected graph\n",
    "num_nodes = X_train_tensor.size(1)  # Number of electrodes\n",
    "edge_index = torch.tensor([(i, j) for i in range(num_nodes) for j in range(num_nodes) if i != j], dtype=torch.long).t().contiguous()\n",
    "edge_attr = None  # No edge attributes\n",
    "# Define GCNN architecture\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(X_train_tensor.size(-1), 32)\n",
    "        self.conv2 = GCNConv(32, 64)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = global_mean_pool(x, torch.zeros(x.size(0), dtype=torch.long))\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = GCN()\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# Prepare data loader\n",
    "train_data = Data(x=X_train_tensor, edge_index=edge_index, edge_attr=edge_attr, y=y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_tensor, edge_index, y_tensor):\n",
    "        self.X_tensor = X_tensor\n",
    "        self.edge_index = edge_index\n",
    "        self.y_tensor = y_tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_tensor)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'x': self.X_tensor[idx],\n",
    "            'edge_index': self.edge_index,\n",
    "            'y': self.y_tensor[idx]\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "# Create a dataset instance\n",
    "train_dataset = CustomDataset(X_train_tensor, edge_index, y_train_tensor)\n",
    "\n",
    "# Create a data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([90, 64, 161, 1])\n",
      "edge_index shape: torch.Size([2, 4032])\n",
      "y_train_tensor shape: torch.Size([90])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
    "print(\"edge_index shape:\", edge_index.shape)\n",
    "print(\"y_train_tensor shape:\", y_train_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heerkubadia/Library/Python/3.9/lib/python/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data loader\n",
    "train_data = Data(x=X_train_tensor, edge_index=edge_index, edge_attr=edge_attr, y=y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader\n",
    "print(len(train_loader))\n",
    "print(len(train_data))\n",
    "\n",
    "for data in train_loader:\n",
    "  \n",
    "    print(data)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 161, 1]) torch.Size([32, 2, 4032]) torch.Size([32])\n",
      "torch.Size([32, 64, 161, 1]) torch.Size([32, 2, 4032]) torch.Size([32])\n",
      "torch.Size([26, 64, 161, 1]) torch.Size([26, 2, 4032]) torch.Size([26])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data['x'].shape, data['edge_index'].shape, data['y'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     14\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "# Training the GCN model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # Set the model to train mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in train_loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            \n",
    "            loss = criterion(out, data.y.view(-1, 1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute training accuracy\n",
    "            predicted = (out > 0.5).float()\n",
    "            correct += (predicted == data.y.view(-1, 1).float()).sum().item()\n",
    "            total += data.y.size(0)\n",
    "\n",
    "            running_loss += loss.item() * data.y.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
